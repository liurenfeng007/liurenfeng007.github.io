I"<blockquote>
  <p>“Yeah It’s on. ”</p>
</blockquote>

<h2 id="海量数据处理思路">海量数据处理思路：</h2>

<ol>
  <li>分而治之</li>
  <li>堆排序</li>
  <li>外排序</li>
  <li>布隆过滤器/BitMap</li>
</ol>

<hr />

<h2 id="海量数据排序">海量数据排序</h2>

<p>使用思想：分治+外排</p>

<p><strong>1TB数据使用32GB内存如何排序</strong></p>

<p>从40个块中分别读取25G/40=0.625G入内存（40 input buffers）。</p>

<p>执行40路合并，并将合并结果临时存储于2GB 基于内存的输出缓冲区中。当缓冲区写满2GB时，写入硬盘上最终文件，并清空输出缓冲区；当40个输入缓冲区中任何一个处理完毕时，写入该缓冲区所对应的块中的下一个0.625GB，直到全部处理完成。</p>

<h2 id="海量数据查找">海量数据查找</h2>

<p>使用思想：BitMap</p>

<p><strong>给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？</strong></p>

<p>用位图/Bitmap的方法，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。</p>

<p>使用思想：布隆过滤器</p>

<p><strong>给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？</strong></p>

<p>假设错误率为0.01，则此时m应大概是n的13倍。</p>

<p>根据这个问题我们来计算下内存的占用，4G=2^32大概是40亿*8大概是340亿，n=50亿，如果按出错率0.01算需要的大概是650亿个bit。</p>

<p>给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url。</p>

<h2 id="海量数据topk">海量数据topK</h2>

<p>使用思想：分治+堆排</p>

<p><strong>有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。</strong></p>

<ol>
  <li>
    <p>顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,…x4999）中。这样每个文件大概是200k左右。如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。</p>
  </li>
  <li>
    <p>对每个小文件，统计每个文件中出现的词以及相应的频率（可以采用trie树/hash_map等），并取出出现频率最大的100个词（可以用含100个结点的最小堆），并把100个词及相应的频率存入文件，这样又得到了5000个文件。下一步就是把这5000个文件进行归并（类似与归并排序）的过程了。</p>
  </li>
</ol>

<h2 id="后记">后记</h2>

<p>TBD</p>

:ET